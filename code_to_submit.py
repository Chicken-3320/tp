# -*- coding: utf-8 -*-
"""Code_to_Submit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i26c0GXRLzz9Rz2-cADzx79-ymLWt4hY
"""

from __future__ import annotations
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Tuple
import os
import re
import sys
import numpy as np
import pandas as pd
from sklearn import set_config
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
import pprint
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.multioutput import MultiOutputRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from lightgbm import LGBMRegressor
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.ensemble import ExtraTreesRegressor
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.multioutput import RegressorChain
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
import lightgbm as lgb
from sklearn.metrics import mean_squared_error, accuracy_score
pd.set_option('display.max_columns', None)
from lightgbm import LGBMClassifier, LGBMRegressor

import warnings
warnings.filterwarnings("ignore")

def bad_line_handler(bad_line):
    print(f"Skipping line: {bad_line}")

df = pd.read_csv(r'D:\College\NUIG\Thesis\BERPublicsearch.txt', sep='\t', on_bad_lines=bad_line_handler,engine='python', encoding='latin1')

"""# Data Preprocessing

## Data Cleaning
"""

df = df.drop(columns=['SA_Code','ThirdWallType_Description','SecondWallType_Description','FirstWallDescription','SecondEnerProdComment','FirstEnerProdComment','SecondWallDescription','FirstWallType_Description','ThirdWallDescription','gsdSHRenewableResources','gsdWHRenewableResources','FirstEnerConsumedComment','SecondEnerConsumedComment','ThirdEnerProdComment','ThirdEnerConsumedComment','FirstEnergyType_Description','SecondEnergyType_Description','ThirdEnergyType_Description','FirstWallIsSemiExposed','SecondWallIsSemiExposed','ThirdWallIsSemiExposed'])

# 1. Areas – must be strictly positive
area_cols = [
    "WallArea","RoofArea","FloorArea","WindowArea","DoorArea",
    "GroundFloorArea","FirstFloorArea","SecondFloorArea","ThirdFloorArea"
]
for col in area_cols:
    df = df[df[col] >= 0]
df.shape

"""### Replacing NaN values with "No Info"
"""

columns_to_update = [
    "StorageLosses", "ManuLossFactorAvail", "SolarHotWaterHeating", "PrimaryCircuitLoss"
]

# Replace NaN with "No Info" in those columns
df[columns_to_update] = df[columns_to_update].fillna("No Info")

columns_to_update = [
    "StorageLosses", "ManuLossFactorAvail", "SolarHotWaterHeating", "PrimaryCircuitLoss","ElecImmersionInSummer","CombiBoiler","KeepHotFacility","InsulationType"
]

# Replace NaN with "No Info" in those columns
df[columns_to_update] = df[columns_to_update].fillna("No Info")

# BER Cannot be negative and realistically highest BER Rating can be over 750
df = df[df['BerRating'] >= 0]

df = df[df['BerRating'] <= 750].reset_index(drop=True)
df.shape

"""-- Source
- The Irish TABULA typology (SEAI-supported stock archetypes) includes several “actual state” pre-1977 houses in the 600–650 kWh/m²/yr range and an electric-heating variant at 733 kWh/m²/yr — a good benchmark for a realistic upper end.
- Case studies of very poor pre-retrofit homes (e.g., Dingle Rd., Cabra) show G values around 458–501 kWh/m²/yr, illustrating that many G’s cluster just above the threshold — the 700s are the outliers. So I took an higher estimate of 750
- https://www.dublincity.ie/built-last-case-studies/energy-renovated-case-studies/case-study-dingle-road-cabra-west-mid-terrace-two-storey-house-1942/

"""

# df.to_csv("Thesis_Data_1.csv", index=False)

df = pd.read_csv("Thesis_Data_1.csv")

# Assuming df is your DataFrame
null_counts = df.isnull().sum()

print(null_counts)

# #For mixed type columns
# mixed_type_columns = [64,65,66,71]

# # Get the column names using their index positions
# column_names = df.columns[mixed_type_columns]

# # Display the first few rows of these columns
# print(df[column_names].head())

"""## Handling Missing Values"""

# 1. Fill simple defaults
simple_defaults = {
    "MainSpaceHeatingFuel": "Heating Oil",
    "MainWaterHeatingFuel": "Heating Oil",
    "InsulationThickness": 30,
    "VentilationMethod": "Natural ventilation",
    "SHRenewableResources": "No",
    "WHRenewableResources": "No",
    "SolarSpaceHeatingSystem": 0,
    "NoOfOpenFlues": 0,
    "NoOfFluelessGasFires": 0,
    "DraftLobby": "NO",
}
df.fillna(simple_defaults, inplace=True)

# 2. Conditional default for PermeabilityTestResult:
#    - If ventilation is 'Natural ventilation' -> use 0.25 ac/h
#    - If ventilation is 'Balanced whole-house mechanical ventilation' (with or without heat recovery) -> use 0.15 ac/h

def default_permeability(row):
    if pd.notna(row['PermeabilityTestResult']):
        return row['PermeabilityTestResult']
    if row['VentilationMethod'].lower().startswith("balanced"):
        return 0.15
    else:
        return 0.25

df['PermeabilityTestResult'] = df.apply(default_permeability, axis=1)

# 3. Conditional default for NoOfChimneys:
#    - For apartments (e.g., 'Ground-floor apartment', 'Apartment') use 0
#    - For other dwelling types use 1

def default_chimneys(row):
    if pd.notna(row['NoOfChimneys']):
        return row['NoOfChimneys']
    dwelling = str(row.get('DwellingTypeDescr', '')).lower()
    if 'apartment' in dwelling:
        return 0
    else:
        return 1

df['NoOfChimneys'] = df.apply(default_chimneys, axis=1)

# 4. Conditional default for NoOfFansAndVents:
#    - For apartments -> default to 1 (often just a bathroom fan)
#    - For other dwellings -> default to 2 (kitchen and bathroom)
def default_fans_vents(row):
    if pd.notna(row['NoOfFansAndVents']):
        return row['NoOfFansAndVents']
    dwelling = str(row.get('DwellingTypeDescr', '')).lower()
    if 'apartment' in dwelling:
        return 1
    else:
        return 2

df['NoOfFansAndVents'] = df.apply(default_fans_vents, axis=1)

# 5. Conditional default for PercentageDraughtStripped:
#    - If building year of construction is unknown, keep at 100% if new; if older, use 80% as a conservative estimate
def default_draught_stripping(row):
    if pd.notna(row['PercentageDraughtStripped']):
        return row['PercentageDraughtStripped']
    year = row.get('Year_of_Construction')
    # Use 100% for new dwellings (year >= 2010), else 80%
    try:
        if pd.notna(year) and int(year) >= 2010:
            return 100
        else:
            return 80
    except:
        return 80

df['PercentageDraughtStripped'] = df.apply(default_draught_stripping, axis=1)

# 6. Optional: Convert certain columns to numeric types
numeric_cols = [
    'InsulationThickness', 'PermeabilityTestResult',
    'NoOfChimneys', 'NoOfOpenFlues', 'NoOfFansAndVents',
    'NoOfFluelessGasFires', 'PercentageDraughtStripped'
]

df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')

# mixed_type_cols = []

# for col in df.select_dtypes(include=['object', 'category']).columns:
#     types_in_col = df[col].map(type).unique()
#     if len(types_in_col) > 1:
#         mixed_type_cols.append((col, types_in_col))

# # Display the results
# for col, types in mixed_type_cols:
#     print(f"Column '{col}' contains multiple types: {types}")

# columns_to_check = [
#     'MainSpaceHeatingFuel',
#     'MainWaterHeatingFuel',
#     'DraftLobby',
#     'VentilationMethod',
#     'StructureType',
#     'SuspendedWoodenFloor',
#     'PermeabilityTest',
#     'PredominantRoofType'
# ]

# for col in columns_to_check:
#     if col in df.columns:
#         print(f"\nUnique values in '{col}':")
#         print(df[col].unique())
#     else:
#         print(f"\nColumn '{col}' not found in DataFrame.")

def clean_text_cols(df, cols, fill_value="No Info"):
    out = df.copy()
    out[cols] = out[cols].astype("string")

    # Strip spaces
    out[cols] = out[cols].apply(lambda s: s.str.strip())

    # Turn empty strings (were whitespace-only) into NA, then fill
    out[cols] = out[cols].replace("", pd.NA)
    out[cols] = out[cols].fillna(fill_value)
    return out

cols_to_clean = [
    "MainSpaceHeatingFuel",
    "MainWaterHeatingFuel",
    "DraftLobby",
    "VentilationMethod",
    "StructureType",
    "SuspendedWoodenFloor",
    "PermeabilityTest",
    "PredominantRoofType",
]

df = clean_text_cols(df, cols_to_clean)

def clean_renewable_resource_cols(df, cols):
    out = df.copy()
    for c in cols:
        out[c] = (
            pd.to_numeric(
                out[c]
                .astype("string")          # handle mixed types
                .str.strip()               # trim spaces
                .replace(re.compile(r"^no$", re.I), "0"),  # "No" -> "0" (case-insensitive)
                errors="coerce"            # anything non-numeric -> NaN
            )
            .fillna(0.0)                   # missing/NaN -> 0.0
            .astype(float)
        )
    return out

# Use it:
cols_rr = ["SHRenewableResources", "WHRenewableResources"]
df = clean_renewable_resource_cols(df, cols_rr)

mixed_type_cols = []

for col in df.select_dtypes(include=['object', 'category']).columns:
    types_in_col = df[col].map(type).unique()
    if len(types_in_col) > 1:
        mixed_type_cols.append((col, types_in_col))

# Display the results
for col, types in mixed_type_cols:
    print(f"Column '{col}' contains multiple types: {types}")

for col in cols_rr:
    if col in df.columns:
        print(col)
        print(df[col].unique())

df = pd.read_csv("Thesis_Data_2.csv")

"""## Feature Selection"""

df = df.sample(n=10000, random_state=42)

for col in df.select_dtypes(include=['object', 'category']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])

target_cols_to_predict = [
    "BerRating",
    "EnergyRating",
    "CO2Rating",
    "UValueWall",
    "UValueRoof",
    "UValueFloor",
    "UValueWindow",
    "UvalueDoor",
]

def Randomforest_model(df: pd.DataFrame, target_cols_to_predict):
    for target_col in target_cols_to_predict:

        print(f"\n=== Predicting Target: {target_col} ===")

        X = df.drop(columns=[target_col])
        y = df[target_col]


# Two models

        if y.dtype == 'object' or pd.api.types.is_categorical_dtype(y):
            task = 'classification'
            model = RandomForestClassifier(random_state=42)
            if not pd.api.types.is_numeric_dtype(y):
                y = y.astype('category').cat.codes
        else:
            task = 'regression'
            model = RandomForestRegressor(random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        if task == 'classification':
            acc = accuracy_score(y_test, y_pred)
            print(f"Accuracy: {acc:.4f}")
        else:
            r2 = r2_score(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            print(f"R²: {r2:.4f}, MSE: {mse:.4f}")




        # Display top 10 feature importances
        importances = model.feature_importances_
        feat_imp = pd.Series(importances, index=X.columns)
        top10 = feat_imp.sort_values(ascending=False).head(10)

        print("Top 10 influential features:")
        print(top10.to_string())

Randomforest_model(df, target_cols_to_predict)

"""#### No use since all target columns are dependent on predicting each other"""

def Random_Forest_no_leakage(df: pd.DataFrame, target_cols_to_predict):
    for target_col in target_cols_to_predict:

        print(f"\n=== Predicting Target: {target_col} ===")

        # Prevent leakage by dropping all target columns from features
        features_to_exclude = target_cols_to_predict
        X = df.drop(columns=features_to_exclude)
        y = df[target_col]



        if pd.api.types.is_categorical_dtype(y) or y.dtype == 'object':
            task = 'classification'
            model = RandomForestClassifier(random_state=42)
            if not pd.api.types.is_numeric_dtype(y):
                y = y.astype('category').cat.codes
        else:
            task = 'regression'
            model = RandomForestRegressor(random_state=42)

# Pre-Processing to Handle Strings ----------------------------------------
        numeric_cols = X.select_dtypes(include=['number', 'bool']).columns.tolist()
        cat_cols = [c for c in X.columns if c not in numeric_cols]

        numeric_tf = SimpleImputer(strategy='median')
        categorical_tf = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('ohe', OneHotEncoder(handle_unknown='ignore'))  # keeps new/rare cats safe
        ])

        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_tf, numeric_cols),
                ('cat', categorical_tf, cat_cols),
            ]
        )

        pipe = Pipeline(steps=[
            ('pre', preprocessor),
            ('model', model),
        ])
# -------------------------------------------------------------------------
        # Train/test split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # Fit & predict
        pipe.fit(X_train, y_train)
        y_pred = pipe.predict(X_test)

        # Evaluate
        if task == 'classification':
            acc = accuracy_score(y_test, y_pred)
            print(f"Accuracy: {acc:.4f}")
        else:
            r2 = r2_score(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            print(f"R²: {r2:.4f}, MSE: {mse:.4f}")

        # Top 10 feature importances
        importances = pipe.named_steps['model'].feature_importances_

        # Get transformed feature names in the same order as ColumnTransformer output
        feature_names = []
        if numeric_cols:
            feature_names.extend(numeric_cols)
        if cat_cols:
            ohe = pipe.named_steps['pre'].named_transformers_['cat'].named_steps['ohe']
            feature_names.extend(ohe.get_feature_names_out(cat_cols).tolist())

        feat_imp = pd.Series(importances, index=feature_names)
        top10 = feat_imp.sort_values(ascending=False).head(10)

        print("Top 10 influential features:")
        print(top10.to_string())

Random_Forest_no_leakage(df, target_cols_to_predict)

df = pd.read_csv("Thesis_Data_2.csv")

selected_columns = [
    "CountyName","DwellingTypeDescr", "Year_of_Construction", "GroundFloorArea(sq m)", "WallArea", "RoofArea", "FloorArea",
    "WindowArea", "DoorArea", "NoStoreys", "MainSpaceHeatingFuel", "MainWaterHeatingFuel", "InsulationType",
    "InsulationThickness", "VentilationMethod", "PermeabilityTestResult", "HeatSystemControlCat",
    "HeatSystemResponseCat", "ThermalMassCategory", "LowEnergyLightingPercent", "SHRenewableResources",
    "WHRenewableResources", "SolarHotWaterHeating", "SolarSpaceHeatingSystem", "NoOfChimneys", "NoOfOpenFlues",
    "NoOfFansAndVents", "NoOfFluelessGasFires", "DraftLobby", "PercentageDraughtStripped", "BerRating", "CO2Rating",
    "UValueWall", "UValueRoof", "UValueFloor", "UValueWindow", "UvalueDoor","EnergyRating"
]

df = df[selected_columns]

df = pd.read_csv("Thesis_Data_2_Reduced.csv")

df = df.sample(n=10000, random_state=42)



Random_Forest_no_leakage(df, target_cols_to_predict)

import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, r2_score, mean_squared_error
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

def lgbm_no_leakage(df: pd.DataFrame, target_cols_to_predict):
    for target_col in target_cols_to_predict:

        print(f"\n=== Predicting Target: {target_col} ===")

        # Prevent leakage by dropping ALL target columns from features
        X = df.drop(columns=target_cols_to_predict).copy()
        y = df[target_col].copy()

        # Identify column types
        num_cols = X.select_dtypes(include=["number", "bool"]).columns.tolist()
        cat_cols = [c for c in X.columns if c not in num_cols]

        # Preprocessing: impute + one-hot encode categoricals (no leakage: fit on train only)
        pre = ColumnTransformer(
            transformers=[
                ("num", SimpleImputer(strategy="median"), num_cols),
                ("cat", Pipeline([
                    ("imputer", SimpleImputer(strategy="most_frequent")),
                    ("ohe", OneHotEncoder(handle_unknown="ignore"))
                ]), cat_cols),
            ],
            remainder="drop",
        )

        # Task & model
        if pd.api.types.is_categorical_dtype(y) or y.dtype == "object":
            task = "classification"
            # encode y if needed
            if not pd.api.types.is_numeric_dtype(y):
                y = y.astype("category").cat.codes
            model = lgb.LGBMClassifier(random_state=42)
            stratify = y
        else:
            task = "regression"
            model = lgb.LGBMRegressor(random_state=42)
            stratify = None

        # Pipeline: preprocessing -> model
        pipe = Pipeline(steps=[("pre", pre), ("model", model)])

        # Split, fit, predict, evaluate
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=stratify
        )
        pipe.fit(X_train, y_train)
        y_pred = pipe.predict(X_test)

        if task == "classification":
            acc = accuracy_score(y_test, y_pred)
            print(f"Accuracy: {acc:.4f}")
        else:
            r2 = r2_score(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            print(f"R²: {r2:.4f}, MSE: {mse:.4f}")

lgbm_no_leakage(df, target_cols_to_predict)

"""-- According to S. Tripath and T. Kumar, “Enhancing energy performance in irish
 dwellings: A machine learning approach to retrofit interventions”, LGBM performs best

## Feature Engineering
"""

df = pd.read_csv("Thesis_Data_2_Reduced.csv")

"""### Coerce numeric columns in calculation"""

numeric_to_coerce = [
    "Year_of_Construction", "GroundFloorArea(sq m)", "WallArea", "RoofArea", "FloorArea",
    "WindowArea", "DoorArea", "NoStoreys", "PermeabilityTestResult",
    "InsulationThickness", "LowEnergyLightingPercent",
    "NoOfChimneys", "NoOfOpenFlues", "NoOfFansAndVents", "NoOfFluelessGasFires",
    "PercentageDraughtStripped",
]
for col in numeric_to_coerce:
    df[col] = pd.to_numeric(df[col], errors="coerce")

"""### Age Features"""

# AgeOfHouse
current_year = pd.Timestamp.now().year
df["AgeOfHouse"] = current_year - df["Year_of_Construction"]
df.loc[df["AgeOfHouse"] < 0, "AgeOfHouse"] = np.nan  # guard against future years

# AgeBand
df["AgeBand"] = pd.cut(
    df["AgeOfHouse"],
    bins=[-np.inf, 29, 49, 79, 109, np.inf],
    labels=["0-29", "30-49", "50-79", "80-109", "110+"]
).astype("object").fillna("Unknown")

"""### Geometry & compactness features (safe division)"""

# Divisors set to NaN to avoid inf
div_wall = df["WallArea"].replace(0, np.nan)
div_floor = df["FloorArea"].replace(0, np.nan)
div_storeys = df["NoStoreys"].replace(0, np.nan)

df["FloorAreaPerStorey"] = df["FloorArea"] / div_storeys
df["Compactness"] = (df["WallArea"] + df["RoofArea"]) / div_floor
df["WindowWallRatio"] = df["WindowArea"] / div_wall
df["DoorWallRatio"] = df["DoorArea"] / div_wall
df["OpeningWallRatio"] = (df["WindowArea"] + df["DoorArea"]) / div_wall

"""### Dwelling type category"""

txt = df["DwellingTypeDescr"].astype(str).str.strip().str.lower()

df["DwellingTypeCategory"] = np.select(
    [
        txt.str.contains("apartment|maisonette"),
        txt.str.contains("terrace"),
        txt.str.contains("semi"),
        txt.str.contains("detached"),
    ],
    ["Apartment", "Terraced", "Semi-detached", "Detached"],
    default="Other",
)

"""### Insulation features"""

# InsulationCategory based on thickness
t = pd.to_numeric(df["InsulationThickness"], errors="coerce")
df["InsulationCategory"] = np.select(
    [t < 0, t < 100, t < 200, t >= 200],
    ["Unknown", "Low", "Medium", "High"],
    default="Unknown"
)

# HasInsulation from InsulationType text
itxt = df["InsulationType"].astype(str).str.strip().str.lower()
df["HasInsulation"] = np.where(
    itxt.isna() | itxt.eq("") | itxt.isin({"none", "no", "nan", "0"}), 0, 1
).astype(int)

"""### Fuel categories (space & water heating)"""

def _fuel_series(s):
    s = s.astype(str).str.strip().str.lower()
    return np.select(
        [
            s.eq("") | s.eq("nan"),
            s.str.contains("gas"),
            s.str.contains("oil"),
            s.str.contains("electric|elec"),
            s.str.contains("wood|solid|peat|coal|briquette|briquet|multi-fuel|multifuel"),
        ],
        ["Unknown", "Gas", "Oil", "Electric", "Solid"],
        default="Other"
    )

df["HeatingFuelCategory"] = _fuel_series(df["MainSpaceHeatingFuel"])
df["WaterHeatingFuelCategory"] = _fuel_series(df["MainWaterHeatingFuel"])

"""### Ventilation category"""

v = df["VentilationMethod"].astype(str).str.strip().str.lower()

df["VentilationCategory"] = np.select(
    [
        v.eq("") | v.eq("nan"),
        v.str.contains("natural"),
        v.str.contains("mechanical|mech"),
        v.str.contains("balanced"),
        v.str.contains("heat") & v.str.contains("recovery"),
    ],
    ["Unknown", "Natural", "Mechanical", "Balanced", "HeatRecovery"],
    default="Other"
)

"""### Airtightness category (from permeability test result)"""

pr = pd.to_numeric(df["PermeabilityTestResult"], errors="coerce")

df["AirTightnessCategory"] = np.where(pr.isna(), "Unknown",
                              np.where(pr <= 3, "High",
                              np.where(pr <= 7, "Medium", "Low")))

"""### Thermal mass (encoded text form)"""

df["ThermalMassCategoryEncoded"] = np.where(
    df["ThermalMassCategory"].isna(), "unknown",
    df["ThermalMassCategory"].astype(str).str.strip().str.lower()
)

"""### Total ventilation openings"""

df["TotalVentilationOpenings"] = df[[
    "NoOfChimneys", "NoOfOpenFlues", "NoOfFansAndVents", "NoOfFluelessGasFires"
]].fillna(0).sum(axis=1)

"""### Low energy lighting category"""

lep = pd.to_numeric(df["LowEnergyLightingPercent"], errors="coerce")

df["LowEnergyLightingCategory"] = np.where(lep.isna(), "Unknown",
                                   np.where(lep < 20, "Low",
                                   np.where(lep < 50, "Medium", "High")))

"""### Renewable count across 4 indicators"""

# Treat non-empty/affirmative or positive numeric as 1, else 0
cols_ren = ["SHRenewableResources", "WHRenewableResources", "SolarHotWaterHeating", "SolarSpaceHeatingSystem"]

# Normalize to strings and numerics
tmp = df[cols_ren].copy()

# For numerics: >0 -> 1
for c in cols_ren:
    # try numeric
    num = pd.to_numeric(tmp[c], errors="coerce")
    # fallback text
    txt = tmp[c].astype(str).str.strip().str.lower()
    tmp[c] = np.where(~num.isna(), (num > 0).astype(int),
              np.where(txt.isin({"", "nan", "no", "none", "false", "0"}), 0, 1))

df["RenewableCount"] = tmp.sum(axis=1).astype(int)

"""### Heating control & response categories (normalized text/ids)"""

# Convert digits to canonical string digits, else keep lowercase string
def _norm_ctrl(s):
    s = s.astype(str).str.strip()
    out = []
    for val in s:
        if val.isdigit():
            out.append(str(int(val)))
        else:
            out.append(val.lower())
    return pd.Series(out, index=s.index)

df["HeatingControlCategory"] = _norm_ctrl(df["HeatSystemControlCat"])
df["HeatingResponseCategory"] = _norm_ctrl(df["HeatSystemResponseCat"])

# df.to_csv("Thesis_Data_2_Feature_Engg.csv", index=False)

df = pd.read_csv("Thesis_Data_2_Reduced.csv")

ENERGY_RATING_COL = "EnergyRating"
COUNTY_COL = "CountyName"
YEAR_COL = "Year_of_Construction"

RATING_ORDER = [
    "A1", "A2", "A3", "B1", "B2", "B3",
    "C1", "C2", "C3", "D1", "D2",
    "E1", "E2", "F", "G",
]

# Construction year bins (CSO-ish)
YEAR_BINS = [
    (1700, 1899), (1900, 1929), (1930, 1949), (1950, 1966),
    (1967, 1977), (1978, 1982), (1983, 1993), (1994, 1999),
    (2000, 2004), (2005, 2009), (2010, 2014), (2015, 2019), (2020, 2024),
]
YEAR_BIN_LABELS = [f"{start}-{end}" for (start, end) in YEAR_BINS]

# Edges for pd.cut: must be one longer than labels, so include lower guard (1699)
YEAR_EDGES = [1699, 1899, 1929, 1949, 1966, 1977, 1982, 1993, 1999, 2004, 2009, 2014, 2019, 2024]
df_eda = df.copy()
df_eda[YEAR_COL] = pd.to_numeric(df_eda[YEAR_COL], errors="coerce") #Just to be sure

"""## Overall distribution of energy ratings"""

counts = (
    df_eda[ENERGY_RATING_COL]
    .value_counts()
    .reindex(RATING_ORDER, fill_value=0)
)

plt.figure(figsize=(10, 6))
sns.barplot(x=counts.index, y=counts.values)
plt.title("Distribution of Building Energy Ratings")
plt.xlabel("Energy Rating")
plt.ylabel("Number of dwellings")
plt.tight_layout()
plt.savefig("rating_distribution.png", dpi=300)
plt.show()

"""## Most common rating by county (summary plot)"""

# --- Count ratings per county ---
counts = (
    df_eda
    .groupby([COUNTY_COL, ENERGY_RATING_COL])
    .size()
    .reset_index(name="freq")
)

# Pick the most common rating for each county (tie-break with RATING_ORDER) ---
order_map = {r: i for i, r in enumerate(RATING_ORDER)}
counts["rating_rank"] = counts[ENERGY_RATING_COL].map(order_map).fillna(len(order_map)).astype(int)

top_by_county = (
    counts
    .sort_values([COUNTY_COL, "freq", "rating_rank"], ascending=[True, False, True])
    .groupby(COUNTY_COL, as_index=False)
    .first()  # after sorting, first row per county is the winner
)

# sort counties alphabetically for the plot
top_by_county = top_by_county.sort_values(COUNTY_COL)

plt.figure(figsize=(14, 7))
bars = plt.bar(top_by_county[COUNTY_COL], top_by_county["freq"])
plt.xticks(rotation=45, ha="right")
plt.xlabel("County")
plt.ylabel("Frequency (count)")
plt.title("Most Common Energy Rating by County (Count of Top Rating)")

# Each bar with the winning rating label
for bar, label in zip(bars, top_by_county[ENERGY_RATING_COL]):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width() / 2, height, str(label), ha="center", va="bottom")

plt.tight_layout()
plt.savefig("most_common_rating_by_county.png", dpi=300)
plt.show()

"""## Rating distribution by construction period (stacked % bars)"""

df_eda["YearBin"] = pd.cut(
    df_eda[YEAR_COL],
    bins=YEAR_EDGES,
    labels=YEAR_BIN_LABELS,
    right=True,
    include_lowest=False
)

# Keep rows with a valid bin
df_year = df_eda[df_eda["YearBin"].notna()].copy()

# counts per bin by rating
counts_by_bin = (
    df_year
    .pivot_table(index="YearBin", columns=ENERGY_RATING_COL, aggfunc="size", fill_value=0)
    .reindex(index=YEAR_BIN_LABELS, columns=RATING_ORDER, fill_value=0)
)

# Convert to percentages ---
row_sums = counts_by_bin.sum(axis=1).replace(0, np.nan)
percent_by_bin = (counts_by_bin.div(row_sums, axis=0).fillna(0) * 100)

plt.figure(figsize=(12, 7))

bottom = np.zeros(len(percent_by_bin), dtype=float)
for rating in RATING_ORDER:
    heights = percent_by_bin[rating].values
    plt.bar(percent_by_bin.index.astype(str), heights, bottom=bottom, label=rating)
    bottom += heights

plt.xticks(rotation=45, ha="right")
plt.title("Energy Rating Distribution by Construction Period")
plt.xlabel("Construction period")
plt.ylabel("Percentage of dwellings (%)")
plt.legend(title="Rating", bbox_to_anchor=(1.02, 1), loc="upper left")
plt.tight_layout()
# plt.savefig("rating_distribution_by_yearbin.png", dpi=300)
plt.show()

"""## Heating fuel vs. CO₂ emissions"""

# compute mean CO₂ rating by heating fuel
fuel_co2_means = (df
                  .groupby('MainSpaceHeatingFuel')['CO2Rating']
                  .mean()
                  .sort_values())

# plot the results
plt.figure(figsize=(10, 5))
sns.barplot(
    x=fuel_co2_means.index,
    y=fuel_co2_means.values,
    palette='viridis'
)
plt.title('Mean CO2 rating by main space heating fuel')
plt.xlabel('Main space heating fuel')
plt.ylabel('Mean CO₂ rating (kg CO2/m2 per year)')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""-- AI usage for making plots aesthetic

## Standard Random Forest Regressor and simple imputer with no feature engineering
"""

df = pd.read_csv("Thesis_Data_2_Reduced.csv")

df = df.sample(n=10000, random_state=42)

RAW_INPUT_FEATURES: List[str] = [
    "DwellingTypeDescr", "Year_of_Construction",
    "GroundFloorArea(sq m)", "WallArea", "RoofArea", "FloorArea",
    "WindowArea", "DoorArea", "NoStoreys",
    "MainSpaceHeatingFuel", "MainWaterHeatingFuel",
    "InsulationType", "InsulationThickness",
    "VentilationMethod", "PermeabilityTestResult",
    "HeatSystemControlCat", "HeatSystemResponseCat",
    "ThermalMassCategory", "LowEnergyLightingPercent",
    "SHRenewableResources", "WHRenewableResources",
    "SolarHotWaterHeating", "SolarSpaceHeatingSystem",
    "NoOfChimneys", "NoOfOpenFlues",
    "NoOfFansAndVents", "NoOfFluelessGasFires",
    "DraftLobby", "PercentageDraughtStripped",
]

TARGET_COLUMNS: List[str] = [
    "BerRating", "CO2Rating",
    "UValueWall", "UValueRoof", "UValueFloor",
    "UValueWindow", "UvalueDoor",
]

RF_PARAMS = dict(
    n_estimators=100,
    random_state=42,
    n_jobs=-1,
    max_depth=2,
    min_samples_split=100,
    min_samples_leaf=5,
    bootstrap=True,
)

def build_preprocessor(X: pd.DataFrame) -> Tuple[ColumnTransformer, List[str], List[str]]:
    """Numerics -> median impute; Categoricals -> most_frequent + OHE."""
    numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]
    categorical_cols = [c for c in X.columns if c not in numeric_cols]

    numeric_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median"))
    ])

    # Handle sklearn versions (sparse_output introduced ~1.2)
    try:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    except TypeError:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse=False)

    categorical_transformer = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", ohe),
    ])

    preprocessor = ColumnTransformer(
        transformers=[
            ("num", numeric_transformer, numeric_cols),
            ("cat", categorical_transformer, categorical_cols),
        ],
        remainder="drop",
        sparse_threshold=0.3,
    )
    return preprocessor, numeric_cols, categorical_cols

def train_models(
    df: pd.DataFrame,
    raw_features: List[str] = RAW_INPUT_FEATURES,
    targets: List[str] = TARGET_COLUMNS,
    test_size: float = 0.2,
    random_state: int = 42,
) -> Tuple[Pipeline, Dict[str, Dict[str, float]], pd.DataFrame, pd.DataFrame]:
    """
    Train a multi-output Random Forest on raw features only.
    Returns: (fitted pipeline, metrics dict, y_test, y_pred_df)
    """
    X = df[raw_features].copy()
    y = df[targets].copy()

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )

    preprocessor, _, _ = build_preprocessor(X)

    reg_model = Pipeline(steps=[
        ("preprocessor", preprocessor),
        ("model", MultiOutputRegressor(RandomForestRegressor(**RF_PARAMS), n_jobs=1)),
    ])

    reg_model.fit(X_train, y_train)
    y_pred = reg_model.predict(X_test)

    # Build metrics
    metrics: Dict[str, Dict[str, float]] = {}
    for idx, col in enumerate(y.columns):
        metrics[col] = {
            "MAE": float(mean_absolute_error(y_test.iloc[:, idx], y_pred[:, idx])),
            "RMSE": float(np.sqrt(((y_test.iloc[:, idx] - y_pred[:, idx])**2).mean())),
            "R2": float(r2_score(y_test.iloc[:, idx], y_pred[:, idx])),
        }

    y_pred_df = pd.DataFrame(y_pred, columns=targets, index=y_test.index)
    return reg_model, metrics, y_test, y_pred_df

# def predict_single(
#     reg_model: Pipeline,
#     user_input: Dict[str, Any],
#     raw_features: List[str] = RAW_INPUT_FEATURES,
#     targets: List[str] = TARGET_COLUMNS,
# ) -> Dict[str, float]:
#     """
#     Predict for one input dict containing raw features only.
#     Missing fields are set to NaN and imputed by the pipeline.
#     """
#     row = {f: user_input.get(f, np.nan) for f in raw_features}
#     X_new = pd.DataFrame([row], columns=raw_features)
#     preds = reg_model.predict(X_new)[0]
#     return {targets[i]: float(preds[i]) for i in range(len(targets))}

reg_model, metrics, y_test, y_pred = train_models(
    df, test_size=0.2, random_state=42
)

# Neat display of metrics
metrics_df = pd.DataFrame(metrics).T[["MAE", "RMSE", "R2"]].sort_values("R2", ascending=False)
metrics_df





"""## Standard Random Forest Regressor and simple imputer with feature engineering"""



df = pd.read_csv("Thesis_Data_2_10k.csv")

RF_PARAMS = dict(
    n_estimators=200,
    random_state=42,
    n_jobs=-1,
    max_depth=5,
    min_samples_split=100,
    min_samples_leaf=5,
    bootstrap=True,
)

reg_model_fe, metrics_fe, y_test_fe, y_pred_fe = train_models(
    df, test_size=0.2, random_state=42
)

metrics_new_2 = (
    pd.DataFrame(metrics_fe)
    .T[["MAE", "RMSE", "R2"]]
    .sort_values("R2", ascending=False)
)
metrics_new_2

models = {
    "v1": metrics_df,        # baseline
    "v2": metrics_new_2,    # (FE run)
}

order_cols = ["MAE", "RMSE", "R2"]

wide = pd.concat(
    {name: m[order_cols] for name, m in models.items()},
    axis=1
)

wide

# Long format for plotting
plot_long = (
    wide.stack(0)  # index: target, model ; columns: MAE, RMSE, R2
    .reset_index()
    .rename(columns={"level_1": "Model", "level_0": "Target"})
)

# R² comparison
pivot_r2 = plot_long.pivot(index="Target", columns="Model", values="R2")
ax = pivot_r2.plot(kind="bar", figsize=(10, 5))
plt.title("R² by target across models")
plt.ylabel("R²")
plt.xlabel("Target")
plt.legend(title="Model")
plt.tight_layout()
plt.show()

"""## Light GBM Regressor and simple imputer with feature engineering"""

df = pd.read_csv("Thesis_Data_2_10k.csv")

df_fe = df

FEATURE_DF = df_fe

FEATURE_COLUMNS: List[str] = [c for c in FEATURE_DF.columns if c not in TARGET_COLUMNS]

# LightGBM params (tweak as needed)
LGBM_REG_PARAMS = dict(
    n_estimators=50,
    learning_rate=0.5,
    num_leaves=2,
    min_child_samples=20,
    subsample=1,
    colsample_bytree=1,
    reg_alpha=2.0,
    reg_lambda=2.0,
    n_jobs=-1,
    verbosity=-1,
    force_col_wise=True,
)

def train_models_lgbm(
    df: pd.DataFrame,
    feature_cols: List[str],
    targets: List[str] = TARGET_COLUMNS,
    test_size: float = 0.2,
    random_state: int = 42,
) -> Tuple[Pipeline, Dict[str, Dict[str, float]], pd.DataFrame, pd.DataFrame]:
    """
    Train multi-output LightGBM on given features (no additional FE here).
    Returns: (pipeline, metrics_dict, y_test_df, y_pred_df)
    """
    X = df[feature_cols].copy()
    y = df[targets].copy()

    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=test_size, random_state=random_state)

    pre, _, _ = build_preprocessor(X)

    model = Pipeline(steps=[
        ("preprocessor", pre),
        ("model", MultiOutputRegressor(LGBMRegressor(**LGBM_REG_PARAMS), n_jobs=1)),
    ])

    model.fit(X_tr, y_tr)
    y_hat = model.predict(X_te)

    metrics: Dict[str, Dict[str, float]] = {}
    for i, col in enumerate(y.columns):
        metrics[col] = {
            "MAE": float(mean_absolute_error(y_te.iloc[:, i], y_hat[:, i])),
            "RMSE": float(np.sqrt(mean_squared_error(y_te.iloc[:, i], y_hat[:, i]))),
            "R2": float(r2_score(y_te.iloc[:, i], y_hat[:, i])),
        }

    y_hat_df = pd.DataFrame(y_hat, columns=targets, index=y_te.index)
    return model, metrics, y_te, y_hat_df

reg_model_lgbm, metrics_lgbm, y_test_lgbm, y_pred_lgbm = train_models_lgbm(
    FEATURE_DF,
    feature_cols=FEATURE_COLUMNS,
    test_size=0.2,
    random_state=42,
)

metrics_lgbm_df = (
    pd.DataFrame(metrics_lgbm)
    .T[["MAE", "RMSE", "R2"]]
    .sort_values("R2", ascending=False)
)
metrics_lgbm_df

comparison_two = pd.concat(
    {
        "RF_v3_new2": metrics_new_2[["MAE", "RMSE", "R2"]],
        "LGBM_FE":    metrics_lgbm_df[["MAE", "RMSE", "R2"]],
    },
    axis=1
)

r2_plot = comparison_two.loc[:, [("RF_v3_new2", "R2"), ("LGBM_FE", "R2")]]
r2_plot.columns = ["RF_v3_new2", "LGBM_FE"]

ax = r2_plot.plot(kind="bar", figsize=(10, 5))
plt.title("R² by target: Random Forest v3_new2 vs LightGBM (FE)")
plt.ylabel("R²")
plt.xlabel("Target")
plt.legend(title="Model")
plt.tight_layout()
plt.show()

"""## HyperParameter Tuning LGBM"""

# data_path = "random_500_rows.csv"  # adjust the path if necessary
# df = pd.read_csv(data_path)

# df_fe = engineer_features(df)
# feature_cols = RAW_INPUT_FEATURES + ENGINEERED_FEATURES
# X = df_fe[feature_cols]
# y = df[TARGET_COLUMNS]

# # ----------------------------
# # 3. Build the preprocessing and modelling pipeline
# # ----------------------------

# preprocessor = build_preprocessor(X)

# # Multi-output regression wrapper around LightGBM
# lgbm_base = LGBMRegressor(boosting_type="gbdt", objective="regression", n_jobs=-1)

# model = Pipeline(steps=[
#     ("preprocessor", preprocessor),
#     ("model", MultiOutputRegressor(lgbm_base, n_jobs=1))
# ])

# # ----------------------------
# # 4. Define hyperparameter search space
# #    (num_leaves, learning_rate, n_estimators etc. are key parameters to tune:contentReference[oaicite:3]{index=3})
# # ----------------------------

# param_distributions = {
#     # number of boosting iterations (trees)
#     "model__estimator__n_estimators": [200, 400, 600, 800],
#     # learning rate controls how quickly the model learns
#     "model__estimator__learning_rate": [0.01, 0.05, 0.1, 0.2],
#     # complexity of each tree: num_leaves should be tuned relative to max_depth:contentReference[oaicite:4]{index=4}
#     "model__estimator__num_leaves": [31, 63, 127],
#     # limit maximum depth explicitly; -1 means no limit
#     "model__estimator__max_depth": [-1, 10, 20, 30],
#     # minimum number of samples per leaf (min_child_samples) to avoid over‑fitting:contentReference[oaicite:5]{index=5}
#     "model__estimator__min_child_samples": [20, 50, 100],
#     # row subsampling and column subsampling
#     "model__estimator__subsample": [0.8, 0.9, 1.0],
#     "model__estimator__colsample_bytree": [0.8, 0.9, 1.0],
#     # L1 and L2 regularization
#     "model__estimator__reg_alpha": [0.0, 0.1, 0.5],
#     "model__estimator__reg_lambda": [0.0, 0.1, 0.5],
# }

# # ----------------------------
# # 5. Define a scoring function for multi-output RMSE
# # ----------------------------

# def rmse_metric(y_true, y_pred):
#     """Negative root mean squared error (negated so that higher is better)."""
#     return -np.sqrt(mean_squared_error(y_true, y_pred))

# scoring = make_scorer(rmse_metric)

# # ----------------------------
# # 6. Run randomized search cross-validation
# #    (uses RandomizedSearchCV for efficiency; you could switch to GridSearchCV
# #     with a smaller grid like the example showing num_leaves, learning_rate and n_estimators:contentReference[oaicite:6]{index=6})
# # ----------------------------

# search = RandomizedSearchCV(
#     estimator=model,
#     param_distributions=param_distributions,
#     n_iter=30,              # number of random combinations to try
#     scoring=scoring,
#     cv=3,                   # 3-fold cross-validation
#     verbose=2,
#     random_state=42,
#     n_jobs=-1
# )

# # Fit the search to data
# search.fit(X, y)

# # Show the best hyperparameters and score
# print("Best hyperparameters found:", search.best_params_)
# print("Best cross-validation score (negative RMSE):", search.best_score_)

# # To get the best model directly
# best_model = search.best_estimator_


## Code block for hyperparameter tuning was generated using AI in order to find the best params

"""-- Names have been interchanged for tuned and untuned dae lgbm

## Best Param Light GBM + Denoising Autoencoder
"""

df = pd.read_csv("Thesis_Data_2_10k.csv")

class AutoencoderImputer(BaseEstimator, TransformerMixin):
    """
    Denoising autoencoder imputer using MLPRegressor.
    Trains to reconstruct numeric features; fills only missing entries at transform time.
    """

    def __init__(
        self,
        hidden_layer_sizes: Tuple[int, ...] = (128, 64, 128),
        activation: str = "relu",
        max_iter: int = 200,
        random_state: Optional[int] = 42,
        mask_prob: float = 0.2,
        learning_rate_init: float = 1e-3,
        alpha: float = 1e-4,
        batch_size: int | str = "auto",
        solver: str = "adam",
    ) -> None:
        self.hidden_layer_sizes = hidden_layer_sizes
        self.activation = activation
        self.max_iter = max_iter
        self.random_state = random_state
        self.mask_prob = mask_prob
        self.learning_rate_init = learning_rate_init
        self.alpha = alpha
        self.batch_size = batch_size
        self.solver = solver

    def fit(self, X: pd.DataFrame, y: Any = None) -> "AutoencoderImputer":
        if not isinstance(X, pd.DataFrame):
            X = pd.DataFrame(X)
        self.columns_ = list(X.columns)
        self.medians_ = X.median(skipna=True).values

        X_filled = X.copy()
        for i, col in enumerate(self.columns_):
            X_filled[col] = X_filled[col].fillna(self.medians_[i])

        orig_missing_mask = X.isna().values
        rng = np.random.RandomState(self.random_state)
        random_mask = rng.rand(*X_filled.shape) < self.mask_prob
        combined_mask = orig_missing_mask | random_mask

        X_noisy = X_filled.to_numpy(dtype=float)
        medians_arr = self.medians_.reshape((1, -1))
        mask_idx = np.where(combined_mask)
        X_noisy[mask_idx] = medians_arr[0, mask_idx[1]]

        mask_features = combined_mask.astype(float)
        X_input = np.concatenate([X_noisy, mask_features], axis=1)
        y_target = X_filled.values

        self.mlp_ = MLPRegressor(
            hidden_layer_sizes=self.hidden_layer_sizes,
            activation=self.activation,
            random_state=self.random_state,
            max_iter=self.max_iter,
            learning_rate_init=self.learning_rate_init,
            alpha=self.alpha,
            batch_size=self.batch_size,
            solver=self.solver,
        )
        self.mlp_.fit(X_input, y_target)
        return self

    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        if not hasattr(self, "mlp_"):
            raise RuntimeError("AutoencoderImputer has not been fitted yet.")
        if not isinstance(X, pd.DataFrame):
            X = pd.DataFrame(X, columns=self.columns_)
        else:
            X = X.copy()

        X_filled = X.copy()
        for i, col in enumerate(self.columns_):
            X_filled[col] = X_filled[col].fillna(self.medians_[i])

        missing_mask = X.isna().values.astype(float)
        X_input = np.concatenate([X_filled.values, missing_mask], axis=1)

        reconstructed = self.mlp_.predict(X_input)

        X_out = X.copy()
        for i, col in enumerate(self.columns_):
            mask = X_out[col].isna()
            if mask.any():
                X_out.loc[mask, col] = reconstructed[mask.values, i]
        return X_out

def build_preprocessor_with_dae(
    X: pd.DataFrame,
    dae_imputer_params: Optional[Dict[str, Any]] = None,
    sparse_threshold: float = 0.3,
) -> Tuple[ColumnTransformer, List[str], List[str]]:
    """
    Builds a ColumnTransformer with:
      - AutoencoderImputer for numeric columns
      - Most-frequent imputation + OneHot for categorical columns
    """
    numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]
    categorical_cols = [c for c in X.columns if c not in numeric_cols]

    num_tf = Pipeline([
        ("imputer", AutoencoderImputer(**(dae_imputer_params or {})))
    ])

    try:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    except TypeError:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse=False)

    cat_tf = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", ohe),
    ])

    pre = ColumnTransformer(
        transformers=[
            ("num", num_tf, numeric_cols),
            ("cat", cat_tf, categorical_cols),
        ],
        remainder="drop",
        sparse_threshold=sparse_threshold,
    )
    return pre, numeric_cols, categorical_cols

def train_models_dae_lgbm(
    df: pd.DataFrame,
    targets: List[str],
    feature_cols: Optional[List[str]] = None,
    *,
    lgbm_params: Dict[str, Any],          # <- REQUIRED
    test_size: float = 0.2,
    random_state: int = 42,
    dae_imputer_params: Optional[Dict[str, Any]] = None,
):
    """
    Train a MultiOutput LightGBM regressor with a DAE imputer in preprocessing.

    Returns: (pipeline, metrics_dict, y_test_df, y_pred_df)
    """
    if feature_cols is None:
        feature_cols = [c for c in df.columns if c not in targets]

    X = df[feature_cols].copy()
    y = df[targets].copy()

    X_tr, X_te, y_tr, y_te = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )

    pre, _, _ = build_preprocessor_with_dae(X, dae_imputer_params=dae_imputer_params)

    model = Pipeline(steps=[
        ("preprocessor", pre),
        ("model", MultiOutputRegressor(LGBMRegressor(**lgbm_params), n_jobs=1)),
    ])

    model.fit(X_tr, y_tr)
    y_hat = model.predict(X_te)

    metrics = {}
    for i, col in enumerate(y.columns):
        mae = float(mean_absolute_error(y_te.iloc[:, i], y_hat[:, i]))
        rmse = float(np.sqrt(mean_squared_error(y_te.iloc[:, i], y_hat[:, i])))
        r2 = float(r2_score(y_te.iloc[:, i], y_hat[:, i]))
        metrics[col] = {"MAE": mae, "RMSE": rmse, "R2": r2}

    y_hat_df = pd.DataFrame(y_hat, columns=targets, index=y_te.index)
    return model, metrics, y_te, y_hat_df

DAE_DEFAULT = dict(
    hidden_layer_sizes=(128, 64, 32, 64, 128),
    activation="tanh",
    max_iter=200,
    random_state=42,
    mask_prob=0.2,
    learning_rate_init=2e-4,
    alpha=1e-4,
    batch_size=64,
    solver="adam",
)

LGBM_DEFAULT = dict(  # Code 1 params
    n_estimators=100,
    learning_rate=0.01,
    num_leaves=20,
    min_child_samples=20,
    subsample=0.7,
    colsample_bytree=0.7,
    reg_alpha=2.0,
    reg_lambda=2.0,
    n_jobs=-1,
    verbosity=-1,
    force_col_wise=True,
)

# Default
reg_model_dae_lgbm_tuned, metrics_dae_lgbm_tuned, y_test_dae_lgbm_tuned, y_pred_dae_lgbm_tuned = train_models_dae_lgbm(
    df,
    targets=TARGET_COLUMNS,
    dae_imputer_params=DAE_TUNED,
    lgbm_params=LGBM_DEFAULT,
    test_size=0.2,
    random_state=42,
)

# Metrics table:
pd.DataFrame(metrics_dae_lgbm_tuned).T[["MAE", "RMSE", "R2"]].sort_values("R2", ascending=False)

"""## HyperParameter Tuning for DAE"""

# import numpy as np
# import pandas as pd
# from pathlib import Path

# from sklearn.model_selection import RandomizedSearchCV
# from sklearn.metrics import make_scorer
# from sklearn.pipeline import Pipeline
# from sklearn.compose import ColumnTransformer
# from sklearn.impute import SimpleImputer
# from sklearn.preprocessing import OneHotEncoder
# from sklearn.multioutput import MultiOutputRegressor

# from lightgbm import LGBMRegressor

# # ----------------------------------------------------------------------
# # 1. Load your data and engineer additional features
# # ----------------------------------------------------------------------
# # This assumes your earlier definitions of RAW_INPUT_FEATURES, ENGINEERED_FEATURES,
# # TARGET_COLUMNS, and the engineer_features function are available in the notebook.
# # If not, copy those definitions here.
# data_path = Path("BER_1kUncleaned_Data.csv")
# df = pd.read_csv(data_path)

# # Engineer extra features (AgeOfHouse, categories, ratios, etc.).
# df_fe = engineer_features(df.copy())
# feature_cols = RAW_INPUT_FEATURES + ENGINEERED_FEATURES

# X = df_fe[feature_cols]
# y = df[TARGET_COLUMNS]

# # ----------------------------------------------------------------------
# # 2. Build preprocessing pipeline
# # ----------------------------------------------------------------------
# # Identify numeric and categorical columns
# numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]
# categorical_cols = [c for c in X.columns if c not in numeric_cols]

# # Create one-hot encoder (with dense output for pandas compatibility)
# try:
#     ohe = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
# except TypeError:
#     # older versions of scikit-learn use 'sparse'
#     ohe = OneHotEncoder(handle_unknown="ignore", sparse=False)

# # Build the ColumnTransformer using the AutoencoderImputer for numeric data
# preprocessor = ColumnTransformer(
#     transformers=[
#         ("num", Pipeline(steps=[
#             ("imputer", AutoencoderImputer())
#         ]), numeric_cols),
#         ("cat", Pipeline(steps=[
#             ("imputer", SimpleImputer(strategy="most_frequent")),
#             ("onehot", ohe)
#         ]), categorical_cols)
#     ],
#     remainder="drop",
#     sparse_threshold=0.3,
# )

# # ----------------------------------------------------------------------
# # 3. Build full modelling pipeline
# # ----------------------------------------------------------------------
# # LightGBM hyper‑parameters are assumed already tuned and fixed here
# lgbm_model = LGBMRegressor(**LGBM_REG_PARAMS)
# multi_output_model = MultiOutputRegressor(lgbm_model, n_jobs=1)

# pipeline = Pipeline(steps=[
#     ("preprocessor", preprocessor),
#     ("model", multi_output_model)
# ])

# # ----------------------------------------------------------------------
# # 4. Define the hyper‑parameter search space for AutoencoderImputer
# # ----------------------------------------------------------------------
# # Tune only the imputer – e.g. hidden layer sizes, activation function,
# # max epochs (max_iter) and the fraction of randomly masked values (mask_prob).
# param_distributions = {
#     "preprocessor__num__imputer__hidden_layer_sizes": [
#         (32,), (64,), (32, 16, 32), (64, 32, 64), (128, 64, 128)
#     ],
#     "preprocessor__num__imputer__activation": [
#         "relu", "tanh"
#     ],
#     "preprocessor__num__imputer__max_iter": [
#         100, 200, 300
#     ],
#     "preprocessor__num__imputer__mask_prob": [
#         0.05, 0.1, 0.2
#     ],
# }

# # ----------------------------------------------------------------------
# # 5. Define a custom multi‑output RMSE scorer
# # ----------------------------------------------------------------------
# # This scorer returns the mean RMSE across all target variables (lower is better).
# def multioutput_rmse(y_true, y_pred):
#     # Compute per‑target MSE, take the square root, then average
#     return float(np.mean(np.sqrt(np.mean((y_pred - y_true) ** 2, axis=0))))

# scorer = make_scorer(multioutput_rmse, greater_is_better=False)

# # ----------------------------------------------------------------------
# # 6. Perform the hyper‑parameter search
# # ----------------------------------------------------------------------
# # Adjust n_iter to control how many random combinations to evaluate.
# # More iterations will give a better chance of finding a good set of parameters.
# search = RandomizedSearchCV(
#     estimator=pipeline,
#     param_distributions=param_distributions,
#     n_iter=10,              # number of parameter sets to sample
#     scoring=scorer,
#     cv=3,                   # 3‑fold cross‑validation
#     verbose=2,
#     n_jobs=-1,
#     random_state=42
# )

# # Fit the search object to the data (this may take some time)
# search.fit(X, y)

# # Retrieve best parameters and corresponding score
# print("Best Autoencoder parameters:", search.best_params_)
# print("Best cross‑validated (negative) RMSE score:", search.best_score_)

# # The best estimator can now be accessed via search.best_estimator_
# best_regressor = search.best_estimator_


## Code block for hyperparameter tuning was generated using AI in order to find the best params

DAE_TUNED = dict(
    hidden_layer_sizes=(64, 32, 64),
    activation="relu",
    max_iter=200,
    random_state=42,
    mask_prob=0.2,
    learning_rate_init=1e-3,
    alpha=1e-4,
    batch_size="auto",
    solver="adam",
)

# LGBM_TUNED = dict(    # Code 2 params
#     n_estimators=100,
#     learning_rate=0.1,
#     num_leaves=31,
#     min_child_samples=20,
#     subsample=1.0,
#     colsample_bytree=1.0,
#     reg_alpha=0.0,
#     reg_lambda=0.0,
#     n_jobs=-1,
#     verbosity=-1,
#     force_col_wise=True,
# )

# Tuned
reg_model_dae_lgbm, metrics_dae_lgbm, y_test_dae_lgbm, y_pred_dae_lgbm = train_models_dae_lgbm(
    df,
    targets=TARGET_COLUMNS,
    dae_imputer_params=DAE_DEFAULT,
    lgbm_params=LGBM_TUNED,
    test_size=0.2,
    random_state=42,
)
pd.DataFrame(metrics_dae_lgbm).T[["MAE", "RMSE", "R2"]].sort_values("R2", ascending=False)

def as_metrics_df(m):
    if isinstance(m, pd.DataFrame):
        df = m.copy()
    else:                        # dict-of-dicts (target -> {MAE, RMSE, R2}) or similar
        df = pd.DataFrame(m).T
    return df.loc[:, ["MAE", "RMSE", "R2"]]

# Build comparable blocks (note: swap default/tuned to match the variable names)
models = {
    "RF_v2":             as_metrics_df(metrics_new_2),
    "LGBM_FE":           as_metrics_df(metrics_lgbm_df),
    "DAE_LGBM_default":  as_metrics_df(metrics_dae_lgbm_tuned),         # default run
    "DAE_LGBM_tuned":    as_metrics_df(metrics_dae_lgbm),   # tuned run
}

# Wide MultiIndex table
wide = pd.concat(models, axis=1)
wide.columns.names = ["Model", "Metric"]

# (Optional) sort rows by the tuned model's R2
if ("DAE_LGBM_tuned", "R2") in wide.columns:
    wide = wide.sort_values(("DAE_LGBM_tuned", "R2"), ascending=False)

# Slice R2 for plotting, keep a specific column order
r2_plot = wide.xs("R2", axis=1, level="Metric").reindex(
    ["RF_v2", "LGBM_FE", "DAE_LGBM_default", "DAE_LGBM_tuned"], axis=1
)

ax = r2_plot.plot(kind="bar", figsize=(11, 5))
plt.title("R² by target: RF_v2 vs LGBM_FE vs DAE+LGBM (default) vs DAE+LGBM (tuned)")
plt.ylabel("R²")
plt.xlabel("Target")
plt.legend(title="Model")
plt.tight_layout()
plt.show()

"""## LGBM + DAE + Chained Regressor"""

df = pd.read_csv("Thesis_Data_2_10k.csv")

LGBM_REG_PARAMS_CHAIN = dict(
    n_estimators=100,
    learning_rate=0.1,
    num_leaves=31,
    min_child_samples=20,
    subsample=1,
    colsample_bytree=1,
    reg_alpha=0.0,
    reg_lambda=0.0,
    n_jobs=-1,
    verbosity=-1,
    force_col_wise=True,
)

def train_models_dae_lgbm_chain_tuned(
    df: pd.DataFrame,
    raw_features: List[str],
    targets: List[str],
    test_size: float = 0.2,
    random_state: int = 42,
) -> Tuple[Pipeline, Dict[str, Dict[str, float]], pd.DataFrame, pd.DataFrame]:
    """
    Train a chained LightGBM model with tuned DAE imputer.
    Returns: (pipeline, metrics_dict, y_test_df, y_pred_df)
    """
    X = df[raw_features].copy()
    y = df[targets].copy()

    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=test_size, random_state=random_state)

    pre, _, _ = build_preprocessor_with_dae(X)

    model = Pipeline(steps=[
        ("preprocessor", pre),
        ("model", RegressorChain(LGBMRegressor(**LGBM_REG_PARAMS_CHAIN))),
    ])

    model.fit(X_tr, y_tr)
    y_hat = model.predict(X_te)

    metrics: Dict[str, Dict[str, float]] = {}
    for i, col in enumerate(y.columns):
        metrics[col] = {
            "MAE": float(mean_absolute_error(y_te.iloc[:, i], y_hat[:, i])),
            "RMSE": float(np.sqrt(((y_te.iloc[:, i] - y_hat[:, i]) ** 2).mean())),
            "R2": float(r2_score(y_te.iloc[:, i], y_hat[:, i])),
        }

    y_hat_df = pd.DataFrame(y_hat, columns=targets, index=y_te.index)
    return model, metrics, y_te, y_hat_df

# ---- Run & store results in NEW variables ----
# Assumes your dataframe is `df` and you already defined RAW_INPUT_FEATURES & TARGET_COLUMNS
reg_model_dae_lgbm_chain_tuned, metrics_dae_lgbm_chain_tuned, y_test_dae_lgbm_chain_tuned, y_pred_dae_lgbm_chain_tuned = \
    train_models_dae_lgbm_chain_tuned(
        df,
        raw_features=RAW_INPUT_FEATURES,
        targets=TARGET_COLUMNS,
        test_size=0.2,
        random_state=42,
    )

metrics_dae_lgbm_chain_tuned_df = (
    pd.DataFrame(metrics_dae_lgbm_chain_tuned)
    .T[["MAE", "RMSE", "R2"]]
    .sort_values("R2", ascending=False)
)

metrics_dae_lgbm_chain_tuned_df  # display

# Build comparable blocks (note: swap default/tuned to match the variable names)
models = {
    "RF_v2":             as_metrics_df(metrics_new_2),
    "LGBM_FE":           as_metrics_df(metrics_lgbm_df),
    "DAE_LGBM_default":  as_metrics_df(metrics_dae_lgbm_tuned),         # default run
    "DAE_LGBM_tuned":    as_metrics_df(metrics_dae_lgbm),
    "DAE_LGBM_tuned_chain": as_metrics_df(metrics_dae_lgbm_chain_tuned_df)# tuned run
}

# Wide MultiIndex table
wide = pd.concat(models, axis=1)
wide.columns.names = ["Model", "Metric"]

# (Optional) sort rows by the tuned model's R2
if ("DAE_LGBM_tuned", "R2") in wide.columns:
    wide = wide.sort_values(("DAE_LGBM_tuned", "R2"), ascending=False)

# Slice R2 for plotting, keep a specific column order
r2_plot = wide.xs("R2", axis=1, level="Metric").reindex(
    ["RF_v2", "LGBM_FE", "DAE_LGBM_default", "DAE_LGBM_tuned","DAE_LGBM_tuned_chain"], axis=1
)

ax = r2_plot.plot(kind="bar", figsize=(11, 5))
plt.title("R² by target: RF_v2 vs LGBM_FE vs DAE+LGBM (default) vs DAE+LGBM (tuned) vs DAE_LGBM_tuned_chain")
plt.ylabel("R²")
plt.xlabel("Target")
plt.legend(title="Model")
plt.tight_layout()
plt.show()

df = pd.read_csv("Thesis_Data_2_10k.csv")

"""## MICE (Iterative Imputer)"""

def build_preprocessor_with_mice(X: pd.DataFrame) -> tuple[ColumnTransformer, list, list]:
    numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]
    categorical_cols = [c for c in X.columns if c not in numeric_cols]

    # MICE for numerics (defaults to BayesianRidge as base estimator)
    num_tf = Pipeline([
        ("imputer", IterativeImputer(
            random_state=42,
            max_iter=10,
            initial_strategy="median",
            sample_posterior=False,
        ))
    ])

    # Most-frequent for categoricals, then OHE
    try:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    except TypeError:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse=False)
    cat_tf = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", ohe),
    ])

    pre = ColumnTransformer(
        transformers=[("num", num_tf, numeric_cols), ("cat", cat_tf, categorical_cols)],
        remainder="drop",
        sparse_threshold=0.3,
    )
    return pre, numeric_cols, categorical_cols

LGBM_REG_PARAMS_MICE = dict(
    n_estimators=100,
    learning_rate=0.1,
    num_leaves=31,
    min_child_samples=20,
    subsample=1,
    colsample_bytree=1,
    reg_alpha=0.0,
    reg_lambda=0.0,
    n_jobs=-1,
    verbosity=-1,
    force_col_wise=True,
)

def train_models_mice_lgbm(
    df: pd.DataFrame,
    targets: list = TARGET_COLUMNS,
    feature_cols: list | None = None,
    test_size: float = 0.2,
    random_state: int = 42,
):
    """
    Train MultiOutput LightGBM with MICE imputation on numeric features.
    Uses all non-target columns if feature_cols is None (works for raw or FE dataframes).
    Returns: (pipeline, metrics_dict, y_test_df, y_pred_df)
    """
    if feature_cols is None:
        feature_cols = [c for c in df.columns if c not in targets]

    X = df[feature_cols].copy()
    y = df[targets].copy()

    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=test_size, random_state=random_state)

    pre, _, _ = build_preprocessor_with_mice(X)

    model = Pipeline(steps=[
        ("preprocessor", pre),
        ("model", MultiOutputRegressor(LGBMRegressor(**LGBM_REG_PARAMS_MICE), n_jobs=1)),
    ])

    model.fit(X_tr, y_tr)
    y_hat = model.predict(X_te)

    metrics = {}
    for i, col in enumerate(y.columns):
        metrics[col] = {
            "MAE": float(mean_absolute_error(y_te.iloc[:, i], y_hat[:, i])),
            "RMSE": float(np.sqrt(((y_te.iloc[:, i] - y_hat[:, i]) ** 2).mean())),
            "R2": float(r2_score(y_te.iloc[:, i], y_hat[:, i])),
        }

    y_hat_df = pd.DataFrame(y_hat, columns=targets, index=y_te.index)
    return model, metrics, y_te, y_hat_df

reg_model_mice_lgbm, metrics_mice_lgbm, y_test_mice_lgbm, y_pred_mice_lgbm = \
    train_models_mice_lgbm(df, test_size=0.2, random_state=42)

metrics_mice_lgbm_df = (
    pd.DataFrame(metrics_mice_lgbm)
    .T[["MAE", "RMSE", "R2"]]
    .sort_values("R2", ascending=False)
)

metrics_mice_lgbm_df  # display

# Build comparable blocks (note: swap default/tuned to match the variable names)
models = {
    "RF_v2":             as_metrics_df(metrics_new_2),
    "LGBM_FE":           as_metrics_df(metrics_lgbm_df),
    "DAE_LGBM_default":  as_metrics_df(metrics_dae_lgbm_tuned),         # default run
    "DAE_LGBM_tuned":    as_metrics_df(metrics_dae_lgbm),
    "DAE_LGBM_tuned_chain": as_metrics_df(metrics_dae_lgbm_chain_tuned_df),
    "MICE_LGBM":     as_metrics_df(metrics_mice_lgbm_df)#tuned run
}

# Wide MultiIndex table
wide = pd.concat(models, axis=1)
wide.columns.names = ["Model", "Metric"]

# (Optional) sort rows by the tuned model's R2
if ("DAE_LGBM_tuned", "R2") in wide.columns:
    wide = wide.sort_values(("DAE_LGBM_tuned", "R2"), ascending=False)

# Slice R2 for plotting, keep a specific column order
r2_plot = wide.xs("R2", axis=1, level="Metric").reindex(
    ["RF_v2", "LGBM_FE", "DAE_LGBM_default", "DAE_LGBM_tuned","DAE_LGBM_tuned_chain","MICE_LGBM"], axis=1
)

ax = r2_plot.plot(kind="bar", figsize=(11, 5))
plt.title("R² by target: RF_v2 vs LGBM_FE vs DAE+LGBM (default) vs DAE+LGBM (tuned) vs DAE_LGBM_tuned_chain vs MICE_LGBM")
plt.ylabel("R²")
plt.xlabel("Target")
plt.legend(title="Model")
plt.tight_layout()
plt.show()

"""## MissForest / One Extra Tree MICE"""

def build_preprocessor_with_mice_tree(X: pd.DataFrame) -> tuple[ColumnTransformer, list, list]:
    numeric_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]
    categorical_cols = [c for c in X.columns if c not in numeric_cols]

    base_estimator = ExtraTreesRegressor(
        n_estimators=100,
        max_depth=12,         # limit tree depth
        max_features=0.6,     # fewer features per split
        min_samples_leaf=5,
        random_state=42,
        n_jobs=1,
    )

    num_tf = Pipeline([
        ("imputer", IterativeImputer(
            estimator=base_estimator,
            max_iter=5,
            n_nearest_features=20,
            initial_strategy="median",
             imputation_order="ascending",
            sample_posterior=False,
            random_state=42,
        ))
    ])

    try:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    except TypeError:
        ohe = OneHotEncoder(handle_unknown="ignore", sparse=False)
    cat_tf = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", ohe),
    ])

    pre = ColumnTransformer(
        transformers=[("num", num_tf, numeric_cols), ("cat", cat_tf, categorical_cols)],
        remainder="drop",
        sparse_threshold=0.3,
    )
    return pre, numeric_cols, categorical_cols

# LGBM_REG_PARAMS_MICE_TREE = dict(
#     n_estimators=600, learning_rate=0.01, num_leaves=63,
#     min_child_samples=20, subsample=0.8, colsample_bytree=0.8,
#     reg_alpha=0.0, reg_lambda=0.0, max_depth=-1, n_jobs=-1,
#     verbosity=-1, force_col_wise=True,
# )

LGBM_REG_PARAMS_MICE_TREE = dict(
    n_estimators=100,
    learning_rate=0.1,
    num_leaves=31,
    min_child_samples=20,
    subsample=1,
    colsample_bytree=1,
    reg_alpha=0.0,
    reg_lambda=0.0,
    n_jobs=-1,
    verbosity=-1,
    force_col_wise=True,
)

def train_models_mice_tree_lgbm(
    df: pd.DataFrame,
    targets: list = TARGET_COLUMNS,
    feature_cols: list | None = None,
    test_size: float = 0.2,
    random_state: int = 42,
):
    """
    MultiOutput LightGBM with tree-based MICE imputation for numeric features.
    Returns: (pipeline, metrics_dict, y_test_df, y_pred_df)
    """
    if feature_cols is None:
        feature_cols = [c for c in df.columns if c not in targets]

    X = df[feature_cols].copy()
    y = df[targets].copy()

    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=test_size, random_state=random_state)

    pre, _, _ = build_preprocessor_with_mice_tree(X)

    model = Pipeline(steps=[
        ("preprocessor", pre),
        ("model", MultiOutputRegressor(LGBMRegressor(**LGBM_REG_PARAMS_MICE_TREE), n_jobs=1)),
    ])

    model.fit(X_tr, y_tr)
    y_hat = model.predict(X_te)

    metrics = {}
    for i, col in enumerate(y.columns):
        metrics[col] = {
            "MAE": float(mean_absolute_error(y_te.iloc[:, i], y_hat[:, i])),
            "RMSE": float(np.sqrt(((y_te.iloc[:, i] - y_hat[:, i]) ** 2).mean())),
            "R2": float(r2_score(y_te.iloc[:, i], y_hat[:, i])),
        }

    y_hat_df = pd.DataFrame(y_hat, columns=targets, index=y_te.index)
    return model, metrics, y_te, y_hat_df

reg_model_mice_tree, metrics_mice_tree, y_test_mice_lgbm, y_pred_mice_lgbm = \
    train_models_mice_tree_lgbm(df, test_size=0.2, random_state=42)

metrics_mice_tree_df = (
    pd.DataFrame(metrics_mice_lgbm)
    .T[["MAE", "RMSE", "R2"]]
    .sort_values("R2", ascending=False)
)

metrics_mice_tree_df

# Build comparable blocks (note: swap default/tuned to match the variable names)
models = {
    "RF_v2":             as_metrics_df(metrics_new_2),
    "LGBM_FE":           as_metrics_df(metrics_lgbm_df),
    "DAE_LGBM_default":  as_metrics_df(metrics_dae_lgbm_tuned),         # default run
    "DAE_LGBM_tuned":    as_metrics_df(metrics_dae_lgbm),
    "DAE_LGBM_tuned_chain": as_metrics_df(metrics_dae_lgbm_chain_tuned_df),
    "MICE_LGBM":     as_metrics_df(metrics_mice_lgbm_df),
    "MissForest": as_metrics_df(metrics_mice_tree_df)
}

# Wide MultiIndex table
wide = pd.concat(models, axis=1)
wide.columns.names = ["Model", "Metric"]

# (Optional) sort rows by the tuned model's R2
if ("DAE_LGBM_tuned", "R2") in wide.columns:
    wide = wide.sort_values(("DAE_LGBM_tuned", "R2"), ascending=False)

# Slice R2 for plotting, keep a specific column order
r2_plot = wide.xs("R2", axis=1, level="Metric").reindex(
    ["RF_v2", "LGBM_FE", "DAE_LGBM_default", "DAE_LGBM_tuned","DAE_LGBM_tuned_chain","MICE_LGBM","MissForest"], axis=1
)

ax = r2_plot.plot(kind="bar", figsize=(11, 5))
plt.title("R² by target: RF_v2 vs LGBM_FE vs DAE+LGBM (default) vs DAE+LGBM (tuned) vs DAE_LGBM_tuned_chain vs MICE_LGBM vs MissForest")
plt.ylabel("R²")
plt.xlabel("Target")
plt.legend(title="Model")
plt.tight_layout()
plt.show()

"""## Evaluating Imputers"""

num_examples = 50  # treat as 12 different people
seed_base = 12345  # reproducibility for masking choices

df_test = df

# Make sure these exist from your earlier cells:
# TARGET_COLUMNS = ["BerRating","CO2Rating","UValueWall","UValueRoof","UValueFloor","UValueWindow","UvalueDoor"]
# RAW_INPUT_FEATURES = [...]   # the raw homeowner-style fields used by your RF models

# Define feature columns for full-models (all non-target columns)
feature_cols = [c for c in df_test.columns if c not in TARGET_COLUMNS]

# Split by dtype (used only for controlled masking below)
numeric_cols = [c for c in feature_cols if pd.api.types.is_numeric_dtype(df_test[c])]
categorical_cols = [c for c in feature_cols if c not in numeric_cols]

# ---------------------------------------------------------------------------
# Pick 12 specific rows and keep their original indices for traceability
samples = (
    df_test
    .sample(n=num_examples, random_state=66)   # reproducible selection
    .reset_index()                            # preserve original index
    .rename(columns={"index": "RowID"})       # RowID = original df_test index
)

# Show which rows (people) were selected and a quick preview
preview_cols = [
    # tweak these if you want a different preview subset
    "CountyName", "DwellingTypeDescr", "Year_of_Construction",
    "GroundFloorArea(sq m)", "NoStoreys", "MainSpaceHeatingFuel"
]
print("=== Selected people (sampled rows) with quick preview ===")
print(
    samples[["RowID"] + [c for c in preview_cols if c in df_test.columns]]
    .to_string(index=False)
)

# ---------------------------------------------------------------------------
# Create “imputation-stress” inputs by masking a few numeric & categorical
# features per person; keep an explicit record of exactly which columns were masked
example_inputs = []
true_values_list = []
mask_records = []  # to log which columns were masked for each person

for i, row in samples.iterrows():
    person_id = i + 1
    row_id = int(row["RowID"])

    # The original, unmodified row (drop helper column)
    orig_row = row.drop(labels=["RowID"]).copy()

    # Make a masked copy
    modified_row = orig_row.copy()

    # Choose which columns to set to NaN (reproducible, different per person)
    # Up to 3 numeric + 2 categorical masked per person (adjust if you like)
    n_num_missing = min(3, len(numeric_cols))
    n_cat_missing = min(2, len(categorical_cols))
    rng = np.random.default_rng(seed_base + i)

    num_missing_cols = sorted(rng.choice(numeric_cols, size=n_num_missing, replace=False).tolist()) if n_num_missing else []
    cat_missing_cols = sorted(rng.choice(categorical_cols, size=n_cat_missing, replace=False).tolist()) if n_cat_missing else []

    for col in num_missing_cols + cat_missing_cols:
        modified_row[col] = np.nan

    # Keep only feature columns for model inputs
    example_inputs.append(modified_row[feature_cols].to_dict())

    # Store true targets for error calculation
    true_values_list.append(orig_row[TARGET_COLUMNS])

    # Log the masking choices with actual column names
    mask_records.append({
        "PersonID": person_id,
        "RowID": row_id,
        "MaskedNumericCols": num_missing_cols,
        "MaskedCategoricalCols": cat_missing_cols,
    })

# Print masking details person-by-person (including which RAW_INPUT_FEATURES ended up NaN)
print("\n=== Masking details per person ===")
for rec in mask_records:
    pid = rec["PersonID"]
    rid = rec["RowID"]
    print(f"\nPerson {pid}  (RowID in df_test: {rid})")
    print("  Masked numeric cols:     ", rec["MaskedNumericCols"])
    print("  Masked categorical cols: ", rec["MaskedCategoricalCols"])

    # Which of the RF raw inputs are missing for this person’s input?
    rf_input = {f: example_inputs[pid-1].get(f, np.nan) for f in RAW_INPUT_FEATURES}
    rf_missing = [k for k, v in rf_input.items() if pd.isna(v)]
    print("  Missing among RAW_INPUT_FEATURES (for RF models):", rf_missing)

# ---------------------------------------------------------------------------
# Build a dictionary of models to test (skip any you haven’t trained this run)
model_vars = [
    ("RF_v2", "reg_model_fe"),                          # RandomForest with FE data
    ("LGBM_FE", "reg_model_lgbm"),                         # LightGBM + SimpleImputer
    ("DAE_LGBM_tuned", "reg_model_dae_lgbm"),        # LGBM + tuned DAE
    ("DAE_LGBM_chain_tuned", "reg_model_dae_lgbm_chain_tuned"),  # Chained LGBM + tuned DAE
    ("MissForest_LGBM", "reg_model_mice_tree"),                  # LGBM + MICE
]



models_to_test = {
    label: globals().get(varname) for (label, varname) in model_vars
}
# Drop any that aren't defined
models_to_test = {k: v for k, v in models_to_test.items() if v is not None}

# ---------------------------------------------------------------------------
# Predict and compute errors
results = []
for model_name, model in models_to_test.items():
    for idx, (input_dict, true_vals) in enumerate(zip(example_inputs, true_values_list)):
        # Prepare input for the correct feature space
        if model_name.startswith("RF"):
            # RF models were trained on RAW_INPUT_FEATURES only
            features = {f: input_dict.get(f, np.nan) for f in RAW_INPUT_FEATURES}
            X_input = pd.DataFrame([features])
        else:
            # Other models use the full engineered feature set
            X_input = pd.DataFrame([input_dict], columns=feature_cols)

        # Predict
        pred_vals = model.predict(X_input)[0]

        # Compute errors for each target
        errors = {}
        for i_t, col in enumerate(TARGET_COLUMNS):
            true_val = float(true_vals[col])
            pred_val = float(pred_vals[i_t])
            abs_err = abs(pred_val - true_val)
            sq_err = (pred_val - true_val) ** 2
            rel_err = 100 * abs_err / (true_val if true_val != 0 else 1.0)
            errors[col] = {
                "True": true_val,
                "Pred": pred_val,
                "AbsoluteError": abs_err,
                "SquaredError": sq_err,
                "RelativeError(%)": rel_err,
            }

        results.append({
            "Model": model_name,
            "PersonID": idx + 1,
            "RowID": int(samples.loc[idx, "RowID"]),
            "Errors": errors,
        })

# ---------------------------------------------------------------------------
# Display detailed errors for each model and person
for res in results:
    print(f"\nModel: {res['Model']} | Person {res['PersonID']} (RowID {res['RowID']})")
    pprint.pprint(res["Errors"])

# ---------------------------------------------------------------------------
# Optional: summarise mean absolute error across people for each model and target
mae_summary = {}
for model_name in models_to_test.keys():
    model_rows = [r for r in results if r["Model"] == model_name]
    if not model_rows:
        continue
    mae_summary[model_name] = {
        col: np.mean([r["Errors"][col]["AbsoluteError"] for r in model_rows])
        for col in TARGET_COLUMNS
    }

mae_df = pd.DataFrame(mae_summary).T
print("\n\nMean Absolute Error per model and target across all people:")
print(mae_df)

mae_df

# === RAW-ONLY IMPUTATION EVAL — scenario variations, no ALL_KNOWN, reuse fitted imputers ===
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Any

# --- Preconditions ---
assert "df_test" in globals(), "df_test not found"
assert "RAW_INPUT_FEATURES" in globals(), "RAW_INPUT_FEATURES not found"

# Use only RAW_INPUT_FEATURES present in df_test
EVAL_RAW: List[str] = [c for c in RAW_INPUT_FEATURES if c in df_test.columns]
assert len(EVAL_RAW) > 0, "None of the RAW_INPUT_FEATURES are in df_test."

num_cols_raw = [c for c in EVAL_RAW if pd.api.types.is_numeric_dtype(df_test[c])]
cat_cols_raw = [c for c in EVAL_RAW if c not in num_cols_raw]

# --------- Helper: extract the fitted numeric imputer + its training column list ---------
def extract_fitted_numeric_imputer(fitted_pipeline) -> Tuple[Any, List[str]]:
    pre = fitted_pipeline.named_steps.get("preprocessor", None)
    if pre is None:
        raise ValueError("No 'preprocessor' step in pipeline")

    num_cols_fit, imputer = None, None
    for name, trans, cols in pre.transformers_:
        if name == "num":
            num_cols_fit = list(cols)
            if hasattr(trans, "named_steps") and "imputer" in trans.named_steps:
                imputer = trans.named_steps["imputer"]
            else:
                imputer = trans
            break
    if imputer is None or num_cols_fit is None:
        raise ValueError("Couldn't locate numeric transformer 'num' with an 'imputer'")
    return imputer, num_cols_fit

# --------- Collect fitted imputers from trained pipelines (no refitting) ---------

candidate_pipelines = {
    "Simple_from_LGBM": globals().get("reg_model_lgbm"),
    "DAE_tuned": globals().get("reg_model_dae_lgbm"),
    "DAE_tuned_chain": globals().get("reg_model_dae_lgbm_chain_tuned"),
    "MissForest(Tree)": globals().get("reg_model_mice_tree"),
}
fitted_numeric_imputers: Dict[str, Dict[str, Any]] = {}
for label, pipe in candidate_pipelines.items():
    if pipe is None:
        continue
    try:
        imp, cols = extract_fitted_numeric_imputer(pipe)
        fitted_numeric_imputers[label] = {"imputer": imp, "num_cols_fit": cols}
        print(f"Attached imputer: {label} | type={type(imp).__name__} | n_cols_fit={len(cols)}")
    except Exception as e:
        print(f"Skipping {label}: {e}")
assert len(fitted_numeric_imputers) > 0, "No fitted imputers could be extracted."

# --------- Scenario definitions (no ALL_KNOWN) ---------
CORE_KEYS_ALL = [
    "CountyName", "DwellingTypeDescr", "Year_of_Construction",
    "GroundFloorArea(sq m)", "NoStoreys", "MainSpaceHeatingFuel"
]
CORE_KEYS = [k for k in CORE_KEYS_ALL if k in EVAL_RAW]

def _choose(rng, items, k):
    items = list(items)
    k = max(0, min(k, len(items)))
    if k == 0:
        return []
    return rng.choice(items, size=k, replace=False).tolist()

def build_known_set(row: pd.Series, scenario: str, rng: np.random.Generator) -> set:
    """
    Return the set of RAW_INPUT_FEATURES the 'user' provides for this scenario.
    Variations control how many of the core fields are known and how many 'other' RAW fields are known.
    """
    others = [c for c in EVAL_RAW if c not in CORE_KEYS]

    if scenario == "CORE_0_plus_8_others":
        # none of the core fields are known; 8 other RAW known
        return set(_choose(rng, others, min(8, len(others))))

    if scenario == "CORE_2_plus_6_others":
        # 2 core fields known, 6 other RAW known
        return set(_choose(rng, CORE_KEYS, min(2, len(CORE_KEYS)))) | set(_choose(rng, others, min(6, len(others))))

    if scenario == "CORE_4_plus_4_others":
        # 4 core fields known, 4 other RAW known
        return set(_choose(rng, CORE_KEYS, min(4, len(CORE_KEYS)))) | set(_choose(rng, others, min(4, len(others))))

    if scenario == "CORE_partial_only":
        # only a subset (2–3) of core fields known; no other RAW provided
        k = 3 if len(CORE_KEYS) >= 3 else min(2, len(CORE_KEYS))
        return set(_choose(rng, CORE_KEYS, k))

    if scenario == "YEAR_unknown_core_plus_others":
        # Year_of_Construction intentionally unknown; 3 other core + 5 others known
        ks = set(CORE_KEYS) - {"Year_of_Construction"} if "Year_of_Construction" in CORE_KEYS else set(CORE_KEYS)
        known_core = set(_choose(rng, ks, min(3, len(ks))))
        return known_core | set(_choose(rng, others, min(5, len(others))))

    if scenario == "SIZE_unknown_core_plus_others":
        # GroundFloorArea(sq m) intentionally unknown; 3 other core + 5 others known
        ks = set(CORE_KEYS) - {"GroundFloorArea(sq m)"} if "GroundFloorArea(sq m)" in CORE_KEYS else set(CORE_KEYS)
        known_core = set(_choose(rng, ks, min(3, len(ks))))
        return known_core | set(_choose(rng, others, min(5, len(others))))

    # Fallback: random 60% of RAW known
    k = max(1, int(0.6 * len(EVAL_RAW)))
    return set(_choose(rng, EVAL_RAW, k))

SCENARIOS = [
    "CORE_0_plus_8_others",
    "CORE_2_plus_6_others",
    "CORE_4_plus_4_others",
    "CORE_partial_only",
    "YEAR_unknown_core_plus_others",
    "SIZE_unknown_core_plus_others",
]

# --------- Sample 6 people ---------
num_examples = 20
samples = (
    df_test.sample(n=min(num_examples, len(df_test)), random_state=66)
           .reset_index()
           .rename(columns={"index": "RowID"})
)

print("=== Selected people (RAW preview) ===")
preview_cols = [c for c in CORE_KEYS_ALL if c in df_test.columns]
print(samples[["RowID"] + preview_cols].to_string(index=False))

# --------- Evaluation loop (NO fitting) ---------
rows_summary = []
detail_errors: Dict[Tuple[int, str, str], pd.DataFrame] = {}
coverage = set()

seed_base = 12345
for i, row in samples.iterrows():
    person_id = i + 1
    row_id = int(row["RowID"])
    true_raw = df_test.loc[row_id, EVAL_RAW]

    for scen in SCENARIOS:
        rng = np.random.default_rng(seed_base + person_id * (1 + hash(scen) % 17))
        known_set = build_known_set(true_raw, scen, rng)

        # RAW numeric columns we will hide (unknown to the 'user')
        hidden_raw_numeric = [c for c in num_cols_raw if c not in known_set and pd.notna(true_raw[c])]
        coverage.update(hidden_raw_numeric)

        for label, pack in fitted_numeric_imputers.items():
            imp = pack["imputer"]
            num_cols_fit = pack["num_cols_fit"]

            # numeric row in the imputer's training space
            true_all_num = df_test.loc[row_id, num_cols_fit].copy()
            masked_all_num = true_all_num.copy()

            # mask only the RAW numerics that are unknown in this scenario AND part of this imputer's fit-set
            hidden_for_this_imputer = [c for c in hidden_raw_numeric if c in num_cols_fit]
            for c in hidden_for_this_imputer:
                masked_all_num[c] = np.nan

            if not hidden_for_this_imputer:
                rows_summary.append({
                    "PersonID": person_id, "RowID": row_id, "Scenario": scen, "Imputer": label,
                    "HiddenNumericCount": 0, "MAE_on_Hidden": np.nan, "HiddenNumericCols": ""
                })
                continue

            X_in = pd.DataFrame([masked_all_num], columns=num_cols_fit)
            imputed_vals = imp.transform(X_in)
            if isinstance(imputed_vals, np.ndarray):
                imputed_series = pd.Series(imputed_vals.reshape(-1), index=num_cols_fit)
            else:
                imputed_series = pd.Series(imputed_vals.iloc[0].values, index=num_cols_fit)

            # errors only on hidden RAW numerics
            true_vals = true_all_num[hidden_for_this_imputer].astype(float)
            pred_vals = imputed_series[hidden_for_this_imputer].astype(float)
            abs_err = (true_vals - pred_vals).abs()
            mae = float(abs_err.mean()) if len(abs_err) else np.nan

            detail_errors[(person_id, scen, label)] = pd.DataFrame({
                "TRUE": true_vals, "IMPUTED": pred_vals, "ABS_ERROR": abs_err
            })

            rows_summary.append({
                "PersonID": person_id,
                "RowID": row_id,
                "Scenario": scen,
                "Imputer": label,
                "HiddenNumericCount": len(hidden_for_this_imputer),
                "MAE_on_Hidden": mae,
                "HiddenNumericCols": ", ".join(hidden_for_this_imputer),
            })

# --------- Summaries ---------
per_input_summary = (
    pd.DataFrame(rows_summary)
      .set_index(["Scenario", "Imputer", "PersonID"])
      .sort_index()
)

scenario_imputer_summary = (
    per_input_summary
      .groupby(["Scenario", "Imputer"])["MAE_on_Hidden"]
      .mean()
      .unstack("Imputer")
      .sort_index()
)

coverage_df = pd.Series([c in coverage for c in num_cols_raw],
                        index=num_cols_raw, name="CoveredByAtLeastOneScenario").to_frame()

scenario_imputer_summary

"""## Single Row"""

def predict_single_model(model, user_input, feature_cols=None, targets=None):
    """
    Convert a user_input dict into a single‑row DataFrame, pass through the model,
    and return a dict of predictions keyed by TARGET_COLUMNS.
    If feature_cols is None, it will infer using df and TARGET_COLUMNS defined in
    the notebook.
    """
    if targets is None:
        targets = TARGET_COLUMNS

    if feature_cols is None:
        # Use all non-target columns from df
        feature_cols = [c for c in df.columns if c not in targets]

    # Fill missing features with NaN (imputer will handle these)
    row = {f: user_input.get(f, np.nan) for f in feature_cols}
    X_new = pd.DataFrame([row], columns=feature_cols)
    preds = model.predict(X_new)[0]
    return {targets[i]: float(preds[i]) for i in range(len(targets))}

# Helper: compute error metrics for each target
def compute_errors(prediction, true_vals):
    errors = {}
    for col, true_val in true_vals.items():
        pred_val = prediction[col]
        errors[col] = {
            "AbsoluteError": abs(pred_val - true_val),
            "SquaredError": (pred_val - true_val) ** 2,
            "RelativeError(%)": 100 * abs(pred_val - true_val) / (true_val if true_val != 0 else 1),
        }
    return errors

# -- Adjust these if you want to try a different input or set of true values --
example_input = {
    "DwellingTypeDescr": "Mid-terrace house",
    "Year_of_Construction": 2020,
    "GroundFloorArea(sq m)": 114.60,
    "WallArea": 57.79,
    "RoofArea": 68.20,
    "FloorArea": 60.80,
    "WindowArea": 18.49,
    "DoorArea": 4.07,
    "NoStoreys": 2,
    "MainSpaceHeatingFuel": "Electricity",
    # (other fields optional)
}

true_values = {
    "BerRating": 41.65,
    "CO2Rating": 8.19,
    "UValueWall": 0.18,
    "UValueRoof": 0.15,
    "UValueFloor": 0.16,
    "UValueWindow": 1.30,
    "UvalueDoor": 1.33,  # note the lower-case 'v' matches the column name
}

# ---------------------------------------------------------------------------
# Helper: generic predictor for any pipeline

# ---------------------------------------------------------------------------
# Predict with tree‑based MICE model
prediction_mice = predict_single_model(
    reg_model_mice_tree,       # your fitted MICE tree model
    example_input,
    feature_cols=FEATURE_COLUMNS,
    targets=TARGET_COLUMNS,
)


# Compute per‑target error statistics
errors_mice = compute_errors(prediction_mice, true_values)

print("MICE tree‑based model predictions:")
pprint.pprint(prediction_mice)
print("\nErrors for MICE tree‑based model:")
pprint.pprint(errors_mice)

# -- Adjust these if you want to try a different input or set of true values --
example_input = {
    "DwellingTypeDescr": "Mid-terrace house",
    # "Year_of_Construction": 2020,
    "GroundFloorArea(sq m)": 114.60,
    "WallArea": 57.79,
    "RoofArea": 68.20,
    "FloorArea": 60.80,
    "WindowArea": 18.49,
    "DoorArea": 4.07,
    "NoStoreys": 2,
    "MainSpaceHeatingFuel": "Electricity",
    # (other fields optional)
}

true_values = {
    "BerRating": 41.65,
    "CO2Rating": 8.19,
    "UValueWall": 0.18,
    "UValueRoof": 0.15,
    "UValueFloor": 0.16,
    "UValueWindow": 1.30,
    "UvalueDoor": 1.33,  # note the lower-case 'v' matches the column name
}

# ---------------------------------------------------------------------------
# Helper: generic predictor for any pipeline

# ---------------------------------------------------------------------------
# Predict with tree‑based MICE model
prediction_mice = predict_single_model(
    reg_model_mice_tree,       # your fitted MICE tree model
    example_input,
    feature_cols=FEATURE_COLUMNS,
    targets=TARGET_COLUMNS,
)


# Compute per‑target error statistics
errors_mice = compute_errors(prediction_mice, true_values)

print("MICE tree‑based model predictions:")
pprint.pprint(prediction_mice)
print("\nErrors for MICE tree‑based model:")
pprint.pprint(errors_mice)































df = pd.read_csv("Thesis_Data_2_10k.csv")





































